{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-06T21:23:37.412175Z","iopub.status.busy":"2022-12-06T21:23:37.411233Z","iopub.status.idle":"2022-12-06T21:24:17.657501Z","shell.execute_reply":"2022-12-06T21:24:17.656080Z","shell.execute_reply.started":"2022-12-06T21:23:37.412125Z"},"trusted":true},"outputs":[],"source":["import subprocess\n","import sys\n","import itertools\n","\n","FILEPATH = \"/kaggle/usr/lib/nlp_project/nlp_project.py\"\n","\n","MODELS = [\"RoBERTa\", \"CueNB\", \"AugNB\"]\n","SUBTASKS = [\"cue_detection\", \"scope_resolution\"]\n","TRAIN_DATASETS = [['bioscope_abstracts', 'sfu'], ['bioscope_abstracts', 'bioscope_full_papers']]\n","\n","# Putting train datasets first so that we get results on each set of train datasets for all models before moving to the next one\n","for (train_datasets, model, subtask) in itertools.product(TRAIN_DATASETS, MODELS, SUBTASKS):\n","    subprocess.run([sys.executable, FILEPATH,\n","                    \"--model\", model,\n","                   \"--subtask\", subtask,\n","                   \"--train-datasets\", *train_datasets])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]"},"vscode":{"interpreter":{"hash":"4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"}}},"nbformat":4,"nbformat_minor":4}
