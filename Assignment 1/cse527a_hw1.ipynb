{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYu8aXQzonA6"
   },
   "source": [
    "# **Assignment 1 - Language Models**\n",
    "#### **Due: September 27 (Tuesday), 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6heZKTDpBqd"
   },
   "source": [
    "## **Notes**\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "Welcome to CSE 527A. The goal for the first assignment is to make sure you are familiar with all the tools you need to complete the programming assignments for the course. \n",
    "\n",
    "Each assignment contains two parts: a written and coding portion. The coding portion for each homework assignment will be delivered through a Colaboratory notebook such as this one. Please use as many as code and markdown cells to run and explain all the steps you took in order to answer each question.\n",
    "\n",
    "### **Comments/Documentation**\n",
    "\n",
    "Please follow PEP 8 style guidelines (https://peps.python.org/pep-0008/) for commenting your code. Furthermore, please remember to manually save your work once in a while. If you are connected to a hosted runtime that if for whatever reason it disconnects you will have to rerun all connected code cells.\n",
    "\n",
    "### **Getting Started**\n",
    "\n",
    "In order to compile code efficiently please pay attention to if you are using a hardware accelerator or not. If you are directly calling libraries like Tensorflow, Keras, or Pytorch, it is advised to switch to a GPU.\n",
    "\n",
    "To access a GPU, go to `Edit->Notebook settings` and in the `Hardware accelerator` dropdown choose `GPU`. \n",
    "As soon as you run a code cell, you will be connected to a cloud instance with a GPU.\n",
    "Try running the code cell below to check that a GPU is connected (select the cell then either click the play button at the top left or press `Ctrl+Enter` or `Shift+Enter`).\n",
    "\n",
    "The free version of Google Colab will provide the necessary hardware for this course. Please keep in mind the RAM and Disk Space that you are allocated and that you are not given an infinite active runtime.\n",
    "\n",
    "If your local machine has a GPU that you find outperforms the cloud GPU then you can follow the necessary documentation to use a GPU with your environment.\n",
    "\n",
    "### **Lost GPU/TPU Access on Colab**\n",
    "\n",
    "If you are not allocated a GPU or cannot connect to a GPU (limits are reached for Collab), Kaggle also provides free access to GPUs and TPUs. Please transfer your work to a Kaggle runtime instance by downloading your file on Colab as a '.ipynb' file and importing the file into Kaggle.\n",
    "\n",
    "### **Submission Instructions**\n",
    "\n",
    "We will use Gradescope for assignment submission. You can upload files individually or as part of a zip file, but if using a zip file be sure you are zipping the files directly and not a folder that contains them. Please note if designated output is cleared, you will receive a 0.\n",
    "\n",
    "To download this notebook, go to `File->Download .ipynb`.  Please rename the file to match the name in our file list. \n",
    "\n",
    "When submitting your ipython notebooks, make sure everything runs correctly if the cells are executed in order starting from a fresh session.  Note that just because a cell runs in your current session doesn't mean it doesn't rely on code that you have already changed or deleted.  If the code doesn't take too long to run, we recommend re-running everything with `Runtime->Restart and run all...`.\n",
    "\n",
    "When you upload your submission to the Gradescope assignment, you should get immediate feedback that confirms your submission was processed correctly. Note that Gradesope will allow you to submit multiple times before the deadline, and we will use the latest submission for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKiZhHZxDynm"
   },
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GR_t_TmDD2cq"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive # one option to load datasets\n",
    "from google.colab import files\n",
    "drive.mount('/content/gdrive')\n",
    "!nvidia-smi -L # check if using GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAXOJeg2s-CE"
   },
   "source": [
    "## **Problem 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIYVOS5YUBFA"
   },
   "source": [
    "## **1.1**\n",
    "\n",
    "Write a program to compute unsmoothed unigrams, bigrams, and trigrams (you may not import nltk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjOb6PN5UO3h"
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW1mvZAiUEAq"
   },
   "source": [
    "## **1.2**\n",
    "\n",
    "Train your model on the Wikitext-2-v1 training corpus (https://huggingface.co/datasets/wikitext). Explain the differences between your most common unigrams, bigrams, trigrams (pad beginning and end of your sentences and please remove puncutation and unknown tokens from corpus).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkheb8MSUPou"
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Op5AfEeGUH5q"
   },
   "source": [
    "## **1.3**\n",
    "\n",
    "Calculate the perplexity for each n-gram (unigram, bigram, and trigram) on all splits (traning, validataion, test sets of Wikitext-2). And, without writing code, discuss what might happen to the perplexity if you continue to increase the number of words in your n-gram (4-gram, 5-gram, etc.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2XCUHbSUR2-"
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7GvYRzjUK9x"
   },
   "source": [
    "## **1.4**\n",
    "\n",
    "Enable Laplace smoothing and Add-K smoothing (0.1,0.05,0.01) to your code. Discuss the changes in perplexity values between n-grams as you try different smoothing methods/values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVkncRe1USvc"
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-ce94w5tAnP"
   },
   "source": [
    "## **Problem 2**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNWxGLhaByZX"
   },
   "source": [
    "(Eisenstein Ch. 6) Using the Pytorch library, train an LSTM language model from the same Wikitext training corpus you used in problem 1. After each epoch of training, compute its perplexity on the Wikitext validation corpus. Stop training when the perplexity stops improving.\n",
    "\n",
    "1. Fully describe your model architecture, hyperparameters, and experimental procedure.\n",
    "2. After each epoch of training, compute your LMâ€™s perplexity on the development data. Plot the development perplexity against # of epochs. Additionally, compute and report the perplexity on test\n",
    "data.\n",
    "3. Compare experimental results such as perplexity and training time between your n-gram and neural models (include smoothed and unsmooth n-grams). Provide graphs that demonstrate your\n",
    "results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gAYjEiJtvJt"
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
